training:
  model_name: "xlm-roberta-base"
  batch_size: 16
  max_length: 128
  learning_rate: 2e-5
  epochs: 3
  save_dir: "checkpoints/"
  eval_split_ratio: 0.1  # from HF train -> use 10% for validation
  early_stopping: false
